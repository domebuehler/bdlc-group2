{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7d9a6-0e03-4ae8-97ad-9b7df5313cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import findspark\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3'\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.appName(\"CSV to Parquet\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c84b3-a3b7-4c49-a5da-af4ddc6b0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRawCsvDataFiles():\n",
    "    import subprocess\n",
    "    p = subprocess.Popen(\"hdfs dfs -ls -d /parkingviolations/rawdata/* | awk '{print $8}' \",\n",
    "                         shell=True,\n",
    "                         stdout=subprocess.PIPE,\n",
    "                         stderr=subprocess.STDOUT)\n",
    "    \n",
    "    csv_files = []\n",
    "    \n",
    "    for line in p.stdout.readlines():\n",
    "        csv_files.append(line.decode().strip())\n",
    "    \n",
    "    p.wait()\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e95ba-9beb-4a15-8d4d-72d8f68669da",
   "metadata": {},
   "source": [
    "# Now for the tricky part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ea61b-5a21-481e-883d-40ec0bf64a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, DateType\n",
    "def getSchema():\n",
    "    return StructType([\n",
    "        StructField(\"summons_number\", IntegerType()),\n",
    "        StructField(\"plate_id\", StringType()),\n",
    "        StructField(\"registration_state\", StringType()),\n",
    "        StructField(\"plate_type\", StringType()),\n",
    "        StructField(\"issue_date\", DateType()),\n",
    "        StructField(\"violation_code\", IntegerType()),\n",
    "        StructField(\"vehicle_body_type\", StringType()),\n",
    "        StructField(\"vehicle_make\", StringType()),\n",
    "        StructField(\"issuing_agency\", StringType()),\n",
    "        StructField(\"street_code1\", IntegerType()),\n",
    "        StructField(\"street_code2\", IntegerType()),\n",
    "        StructField(\"street_code3\", IntegerType()),\n",
    "        StructField(\"vehicle_expiration_date\", IntegerType()),\n",
    "        StructField(\"violation_location\", StringType()),\n",
    "        StructField(\"violation_precinct\", IntegerType()),\n",
    "        StructField(\"issuer_precinct\", IntegerType()),\n",
    "        StructField(\"issuer_code\", IntegerType()),\n",
    "        StructField(\"issuer_command\", StringType()),\n",
    "        StructField(\"issuer_squad\", StringType()),\n",
    "        StructField(\"violation_time\", StringType()),\n",
    "        StructField(\"time_first_observed\", StringType()),\n",
    "        StructField(\"violation_county\", StringType()),\n",
    "        StructField(\"violation_in_front_of_or_opposite\", StringType()),\n",
    "        StructField(\"house_number\", StringType()),\n",
    "        StructField(\"street_name\", StringType()),\n",
    "        StructField(\"intersecting_street\", StringType()),\n",
    "        StructField(\"date_first_observed\", IntegerType()),\n",
    "        StructField(\"law_section\", IntegerType()),\n",
    "        StructField(\"sub_division\", StringType()),\n",
    "        StructField(\"violation_legal_code\", StringType()),\n",
    "        StructField(\"days_parking_in_effect\", StringType()),\n",
    "        StructField(\"from_hours_in_effect\", StringType()),\n",
    "        StructField(\"to_hours_in_effect\", StringType()),\n",
    "        StructField(\"vehicle_color\", StringType()),\n",
    "        StructField(\"unregistered_vehicle\", StringType()),\n",
    "        StructField(\"vehicle_year\", IntegerType()),\n",
    "        StructField(\"meter_number\", StringType()),\n",
    "        StructField(\"feet_from_curb\", IntegerType()),\n",
    "        StructField(\"violation_post_code\", StringType()),\n",
    "#StructField(\"violation_description\", StringType()),\n",
    "        StructField(\"no_standing_or_stopping_violation\", StringType()),\n",
    "        StructField(\"hydrant_violation\", StringType()),\n",
    "        StructField(\"double_parking_violation\", StringType())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b734b6-4910-490f-81c2-6e3c0317a80f",
   "metadata": {},
   "source": [
    "## Extract excel with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72cfe9-4362-4909-8421-2c93ef23839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_violation_codes_df():\n",
    "    pandas_df = pd.read_excel(\"../1_Hands-on/Codes-Mapping.xlsx\", skiprows=1)\n",
    "    pandas_df.columns = ['violation_code', 'violation_description', 'manhattan_96th_st_below', 'all_other_areas']\n",
    "    return spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d2e61-cacd-41af-a33c-9dd68734cb70",
   "metadata": {},
   "source": [
    "## Transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba0700-7a19-45eb-80ce-799fc8c26664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, to_timestamp, expr, regexp_replace\n",
    "\n",
    "def transform_csv_to_df(csv_file):\n",
    "\n",
    "    schema = getSchema()\n",
    "\n",
    "    # Read csv with schema\n",
    "    df_raw = spark.read.csv(csv_file, header=True, schema=schema)\n",
    "    \n",
    "    # columns to underscore case\n",
    "    df = df_raw.select([col(col_name).alias(col_name.lower().replace(' ', '_')) for col_name in df_raw.columns])\n",
    "\n",
    "    \n",
    "    #this was generated because data is inconsistent\n",
    "    \n",
    "    # Data cleaning: Preprocess violation_time column\n",
    "    df = df.withColumn(\"violation_time\",\n",
    "                           regexp_replace(\"violation_time\", r'[^\\dAP]', \"\")  # Keep only digits, 'A', and 'P'\n",
    "                          )\n",
    "\n",
    "    # Add leading zeros to hours if needed\n",
    "    df = df.withColumn(\"violation_time\",\n",
    "                       regexp_replace(\"violation_time\", r'(\\d{1,2})(AM|PM)', r'0\\1:\\2')  # Add leading zero to single-digit hour\n",
    "                      )\n",
    "\n",
    "    # Add leading zeros to minutes if needed\n",
    "    df = df.withColumn(\"violation_time\",\n",
    "                       regexp_replace(\"violation_time\", r'(AM|PM)(\\d{1,2})', r'\\1:0\\2')  # Add leading zero to single-digit minute\n",
    "                      )\n",
    "\n",
    "    # Handle edge case for '120AM' -> '12:00 AM'\n",
    "    df = df.withColumn(\"violation_time\",\n",
    "                       regexp_replace(\"violation_time\", r'(12)(AM)', r'00:\\2')  # Replace '12AM' with '00'\n",
    "                      )\n",
    "\n",
    "    # Convert to timestamp\n",
    "    df = df.withColumn(\"violation_time\", \n",
    "                       when(df[\"violation_time\"].isNotNull(), \n",
    "                            to_timestamp(\"violation_time\", \"hh:mma\")\n",
    "                           )\n",
    "                      .otherwise(None)\n",
    "                     )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675f7418-aa73-446f-b517-d0fa37c3a9fc",
   "metadata": {},
   "source": [
    "# Now we combine all dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019dde64-dcfb-4999-98a5-da01d8446e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dfs = []\n",
    "for csvFile in getRawCsvDataFiles():\n",
    "    my_dfs.append(transform_csv_to_df(csvFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce88a7d0-6eef-408b-8419-b22f455f5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "meta_df = get_violation_codes_df()\n",
    "df = reduce(DataFrame.unionAll, my_dfs)\n",
    "\n",
    "df = df.join(meta_df, on=\"violation_code\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59629bf4-bf11-477a-9dbe-6ebac607aa11",
   "metadata": {},
   "source": [
    "## Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29425fb-8d9b-4012-9296-42a871b8527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r /parkingviolations/raw_all.parquet/\n",
    "df.repartition(44).write.parquet(f\"/parkingviolations/raw_all.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bbd402-799f-4a46-a4a9-f99dff051380",
   "metadata": {},
   "source": [
    "## Stop Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de21fcf-5dbc-4810-a641-d1f3082fb0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
