{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f3aeef-b695-40ef-b55f-1e05447d1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb1d587-dff1-4352-ae81-d293616942fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3'\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3870565-96e5-408f-890e-d22604ee5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"lets do some querying\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e49037-42a2-48ec-8c9b-a62099359fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(f\"/parkingviolations/raw_all.parquet\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15879a58-6b9b-4d43-9bda-8e96c054af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14706613",
   "metadata": {},
   "source": [
    "## Question 1: What's the most amount that was paid in violations and by which Plate ID?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd25b3-50b4-4590-adf4-70e0b2be221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.filter((df.plate_id != \"BLANKPLATE\") & (df.plate_id != \"N/A\"))\n",
    "\n",
    "violations_count = filtered_df.groupBy(\"plate_id\", \"vehicle_make\").count()\n",
    "\n",
    "top_violated_plates = violations_count.orderBy(\"count\", ascending=False).limit(10)\n",
    "\n",
    "top_violated_plates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80a9ece-1b1f-465e-9659-b6755fc22b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, col, format_number, count\n",
    "\n",
    "grouped_df = df.groupBy(\"violation_code\", \"violation_description\") \\\n",
    "    .agg(sum(\"all_other_areas\").alias(\"total_fine\"), count(\"*\").alias(\"violation_count\"))\n",
    "\n",
    "sorted_df = grouped_df.orderBy(col(\"total_fine\").desc()) \\\n",
    "    .withColumn(\"total_fine\", format_number(col(\"total_fine\"), 0))\n",
    "\n",
    "sorted_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a1998c",
   "metadata": {},
   "source": [
    "## Question 2: At what hour of the day is it most likely to get a ticket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, col\n",
    "\n",
    "# hour extraction\n",
    "df_with_hour = df.withColumn(\"issue_hour\", hour(col(\"issue_datetime\")))\n",
    "\n",
    "# tickets per hour\n",
    "hourly_ticket_counts = df_with_hour.groupBy(\"issue_hour\").count()\n",
    "\n",
    "# Hour with the highest amounts of tickets issued\n",
    "most_likely_hour = hourly_ticket_counts.orderBy(col(\"count\").desc()).first()\n",
    "most_likely_hour_of_day = most_likely_hour[\"issue_hour\"]\n",
    "ticket_count_at_peak_hour = most_likely_hour[\"count\"]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the total number of tickets for percentages\n",
    "total_tickets = df_with_hour.count()\n",
    "\n",
    "# Calculate the percentage likelihood for each hour\n",
    "hourly_ticket_counts = hourly_ticket_counts.withColumn(\n",
    "    \"likeliness_percentage\",\n",
    "    (col(\"count\") / total_tickets) * 100\n",
    ")\n",
    "\n",
    "# Show results\n",
    "print(f\"Most likely hour to get a ticket is: {most_likely_hour_of_day}\")\n",
    "print(f\"The number of tickets issued during that hour: {ticket_count_at_peak_hour}\")\n",
    "hourly_ticket_counts.orderBy(hourly_ticket_counts.likeliness_percentage.desc()) \\\n",
    ".show(24, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbbc02d",
   "metadata": {},
   "source": [
    "## Question 3: Which percentage of the total violation \"income\" has been provided by the top 10% (top 10% amount of tickets)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690628d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, desc, sum as _sum\n",
    "\n",
    "# Calculate the total number of tickets issued for each violator\n",
    "#Filtering out the dumb ones\n",
    "violator_ticket_counts = df.filter((df.plate_id != \"BLANKPLATE\") & (df.plate_id != \"N/A\")) \\\n",
    ".groupBy(\"plate_id\").count()\n",
    "\n",
    "# Calculate the threshold to find the top 10% violators\n",
    "total_violators = violator_ticket_counts.count()\n",
    "top_10_percent_threshold = int(total_violators * 0.10)\n",
    "\n",
    "# Get the top 10% violators\n",
    "top_10_percent_violators = violator_ticket_counts.orderBy(desc(\"count\")).limit(top_10_percent_threshold)\n",
    "\n",
    "# Join with the original dataframe to filter rows for the top 10% violators\n",
    "top_10_percent_df = df.join(top_10_percent_violators, on=\"plate_id\", how=\"inner\")\n",
    "\n",
    "# Calculate the total fine amount for the top 10% violators\n",
    "total_fine_top_10_percent = top_10_percent_df.agg(_sum(\"fine_amount\").alias(\"total_fine\")).collect()[0][\"total_fine\"]\n",
    "\n",
    "# Calculate the total fine amount for all violators\n",
    "total_fine_all = df.agg(_sum(\"fine_amount\").alias(\"total_fine\")).collect()[0][\"total_fine\"]\n",
    "\n",
    "# Calculate the percentage\n",
    "percentage_fine_top_10_percent = (total_fine_top_10_percent / total_fine_all) * 100\n",
    "\n",
    "print(percentage_fine_top_10_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb9b923-2bca-4ca0-9563-5f880deeafb9",
   "metadata": {},
   "source": [
    "## Question 4: Top 10 Most issued violations and how much money the bring in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4cba27-b0ff-46f5-9c4a-76003748d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Group by violation code and sum the fine amount\n",
    "violation_counts = df.groupBy(\"violation_code\", \"violation_description\") \\\n",
    "    .agg({\"fine_amount\": \"sum\"}) \\\n",
    "    .withColumnRenamed(\"sum(fine_amount)\", \"total_fine\") \\\n",
    "    .orderBy(col(\"total_fine\").desc()) \\\n",
    "    .limit(10)  # Select the top 10 violations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c32722-e06c-49ca-8ff8-97081ab15bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Extracting data for plotting\n",
    "codes = violation_counts.select(\"violation_code\").rdd.flatMap(lambda x: x).collect()\n",
    "descriptions = violation_counts.select(\"violation_description\").rdd.flatMap(lambda x: x).collect()\n",
    "total_fines = violation_counts.select(\"total_fine\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Function to format large numbers\n",
    "def format_large_numbers(x, pos):\n",
    "    if x >= 1e9:\n",
    "        return '{:,.0f}B'.format(x * 1e-9)\n",
    "    elif x >= 1e6:\n",
    "        return '{:,.0f}M'.format(x * 1e-6)\n",
    "    elif x >= 1e3:\n",
    "        return '{:,.0f}K'.format(x * 1e-3)\n",
    "    else:\n",
    "        return '{:,.0f}'.format(x)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(descriptions, total_fines, color='skyblue')\n",
    "plt.xlabel('Total Fine Amount')\n",
    "plt.ylabel('Violation Description')\n",
    "plt.title('Top 10 Most Issued Violations and Their Total Fine Amounts')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the highest fine at the top\n",
    "plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(format_large_numbers))  # Apply the formatting function to x-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1898b-164e-49e2-914e-a82d8daedfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1062708a37074d70712b695aadee582e0b0b9f95f45576b5521424137d05fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
